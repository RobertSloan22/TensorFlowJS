<!doctype html>
<html lang="en" data-bs-theme="auto">
  <head><script src="/docs/5.3/assets/js/color-modes.js"></script>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>TensorFlowJS</title>

    <link rel="canonical" href="https://getbootstrap.com/docs/5.3/examples/jumbotron/">

    

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@docsearch/css@3">

<link href="/docs/5.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-T3c6CoIi6uLrA9TneNEoa7RxnatzjcDSCmG1MXxSR1GAsXEV/Dwwykc2MPK8M2HN" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.11.0/dist/tf.min.js" type="text/javascript"></script>

    <!-- Favicons -->
<link rel="apple-touch-icon" href="/docs/5.3/assets/img/favicons/apple-touch-icon.png" sizes="180x180">
<link rel="icon" href="/docs/5.3/assets/img/favicons/favicon-32x32.png" sizes="32x32" type="image/png">
<link rel="icon" href="/docs/5.3/assets/img/favicons/favicon-16x16.png" sizes="16x16" type="image/png">
<link rel="manifest" href="/docs/5.3/assets/img/favicons/manifest.json">
<link rel="mask-icon" href="/docs/5.3/assets/img/favicons/safari-pinned-tab.svg" color="#712cf9">
<link rel="icon" href="/docs/5.3/assets/img/favicons/favicon.ico">
<meta name="theme-color" content="#712cf9">
    <style>
      .bd-placeholder-img {
        font-size: 1.125rem;
        text-anchor: middle;
        -webkit-user-select: none;
        -moz-user-select: none;
        user-select: none;
      }

      @media (min-width: 768px) {
        .bd-placeholder-img-lg {
          font-size: 3.5rem;
        }
            }
      /* Base styles here */
      
      /* Responsive styles */
      @media (max-width: 768px) {
        body {
          font-size: 14px;
        }
      
        .container {
          padding: 20px;
      }
    
  /* Adjust layout, font sizes, and more for smaller screens */
    }
            .container {
        width: 100%;
        max-width: 1200px; /* or any maximum size */
        margin: 0 auto; /* centers the layout */
      }
      
      .column {
        float: left;
        width: 50%; /* Example: for 2 columns layout */
      }
      
      /* Clearfix for floating elements */
      .row::after {
        content: "";
        clear: both;
        display: table;
      }

      .b-example-divider {
        width: 100%;
        height: 3rem;
        background-color: rgba(0, 0, 0, .1);
        border: solid rgba(0, 0, 0, .15);
        border-width: 1px 0;
        box-shadow: inset 0 .5em 1.5em rgba(0, 0, 0, .1), inset 0 .125em .5em rgba(0, 0, 0, .15);
      }

      .b-example-vr {
        flex-shrink: 0;
        width: 1.5rem;
        height: 100vh;
      }
            img, video {
        max-width: 100%;
        height: auto;
            }
              @media (max-width: 768px) {
        body {
          font-size: 16px;
          line-height: 1.5;
        }
      }

      .bi {
        vertical-align: -.125em;
        fill: currentColor;
      }

      .nav-scroller {
        position: relative;
        z-index: 2;
        height: 2.75rem;
        overflow-y: hidden;
      }

      .nav-scroller .nav {
        display: flex;
        flex-wrap: nowrap;
        padding-bottom: 1rem;
        margin-top: -1px;
        overflow-x: auto;
        text-align: center;
        white-space: nowrap;
        -webkit-overflow-scrolling: touch;
      }

      .btn-bd-primary {
        --bd-violet-bg: #712cf9;
        --bd-violet-rgb: 112.520718, 44.062154, 249.437846;

        --bs-btn-font-weight: 600;
        --bs-btn-color: var(--bs-white);
        --bs-btn-bg: var(--bd-violet-bg);
        --bs-btn-border-color: var(--bd-violet-bg);
        --bs-btn-hover-color: var(--bs-white);
        --bs-btn-hover-bg: #6528e0;
        --bs-btn-hover-border-color: #6528e0;
        --bs-btn-focus-shadow-rgb: var(--bd-violet-rgb);
        --bs-btn-active-color: var(--bs-btn-hover-color);
        --bs-btn-active-bg: #5a23c8;
        --bs-btn-active-border-color: #5a23c8;
      }

      .bd-mode-toggle {
        z-index: 1500;
      }

      .bd-mode-toggle .dropdown-menu .active .bi {
        display: block !important;
      }
    </style>

    // Add mobile-specific styles
    <style>
      @media (max-width: 768px) {
        #webcam {
          width: 100%;
          max-width: 640px;
          height: auto;
          border-radius: 8px;
          margin-bottom: 20px;
        }

        .btn {
          padding: 15px;
          font-size: 16px;
          margin-bottom: 10px;
          touch-action: manipulation;
        }

        #status {
          font-size: 14px;
          padding: 10px;
          background-color: #f8f9fa;
          border-radius: 5px;
          margin: 10px 0;
        }

        .container {
          padding: 10px;
        }
      }
    </style>

    
  </head>
  <body>
    <header>
    
        <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.11.0/dist/tf.min.js" type="text/javascript"></script>

<main>
  <div class="container py-4">
    <header class="pb-3 mb-4 border-bottom">
      <a href="/" class="d-flex align-items-center text-body-emphasis text-decoration-none">
        <span class="fs-4">TensorFlow Java Script - Deep Neural Network </span>
      </a>
    </header>

    <div class="p-5 mb-4 bg-body-tertiary rounded-3">
      <div class="container-fluid py-5">
        <h1 class="display-5 fw-bold">TensorFlow.js Transfer Learning Demo: Robert Sloan</h1>
        
        <h2>Deep Neural Network In the Browser</h2>   

        <div class="d-flex align-items-center" id="status">
          <strong role="status">Awaiting TF.js load</strong>
          <div class="spinner-border ms-auto" id="loadingIndicator" style="visibility: visible;" role="status" aria-hidden="false"></div>
        </div>
   
        <div id="container" class="mt-4">
          <video id="webcam" autoplay muted playsinline></video>
        </div>

        <div class="mt-4">
          <button id="enableCam" class="btn btn-success btn-lg w-100">Enable Webcam</button>
          <button id="switchCam" class="btn btn-secondary btn-lg w-100 mt-2 d-none">Switch Camera</button>
        </div>

        <div class="mt-3 text-center">
          <button class="dataCollector btn btn-primary btn-lg w-100 mb-3" data-1hot="0" data-name="Class 1">Gather Class 1 Data</button>
          <button class="dataCollector btn btn-primary btn-lg w-100 mb-3" data-1hot="1" data-name="Class 2">Gather Class 2 Data</button>
          <button id="train" class="btn btn-warning btn-lg w-100 mb-3">Train &amp; Predict!</button>
          <button id="reset" class="btn btn-danger btn-lg w-100">Reset</button>
        </div>

        <p class="mt-4 text-muted">Training takes 10-15 seconds. Hold down the gather buttons to collect data.</p>
      </div>
    </div>

    <footer class="pt-3 mt-4 text-body-secondary border-top">
      &copy; 2023
    </footer>
  </div>

  <script>
    const STATUS = document.getElementById('status');
    const VIDEO = document.getElementById('webcam');
    const ENABLE_CAM_BUTTON = document.getElementById('enableCam');
    const SWITCH_CAM_BUTTON = document.getElementById('switchCam');
    const RESET_BUTTON = document.getElementById('reset');
    const TRAIN_BUTTON = document.getElementById('train');
    const MOBILE_NET_INPUT_WIDTH = 224;
    const MOBILE_NET_INPUT_HEIGHT = 224;
    const STOP_DATA_GATHER = -1;
    const CLASS_NAMES = [];

    // Initialize variables
    let mobilenet = undefined;
    let gatherDataState = STOP_DATA_GATHER;
    let videoPlaying = false;
    let trainingDataInputs = [];
    let trainingDataOutputs = [];
    let examplesCount = [];
    let predict = false;

    // Camera state
    let currentFacingMode = 'user';
    let stream = null;

    // Setup event listeners
    ENABLE_CAM_BUTTON.addEventListener('click', enableCam);
    SWITCH_CAM_BUTTON.addEventListener('click', switchCamera);
    TRAIN_BUTTON.addEventListener('click', trainAndPredict);
    RESET_BUTTON.addEventListener('click', reset);

    // Setup data collector buttons
    let dataCollectorButtons = document.querySelectorAll('button.dataCollector');
    for (let i = 0; i < dataCollectorButtons.length; i++) {
      dataCollectorButtons[i].addEventListener('touchstart', gatherDataForClass);
      dataCollectorButtons[i].addEventListener('touchend', gatherDataForClass);
      dataCollectorButtons[i].addEventListener('mousedown', gatherDataForClass);
      dataCollectorButtons[i].addEventListener('mouseup', gatherDataForClass);
      CLASS_NAMES.push(dataCollectorButtons[i].getAttribute('data-name'));
    }

    function hasGetUserMedia() {
      return !!(navigator.mediaDevices && navigator.mediaDevices.getUserMedia);
    }

    async function enableCam() {
      if (!hasGetUserMedia()) {
        STATUS.innerText = 'Camera access not supported by your browser';
        return;
      }

      STATUS.innerText = 'Requesting camera permission...';
      ENABLE_CAM_BUTTON.disabled = true;

      try {
        const constraints = {
          video: {
            facingMode: currentFacingMode,
            width: { ideal: 640 },
            height: { ideal: 480 }
          }
        };

        stream = await navigator.mediaDevices.getUserMedia(constraints);
        VIDEO.srcObject = stream;
        
        VIDEO.addEventListener('loadeddata', function() {
          videoPlaying = true;
          ENABLE_CAM_BUTTON.classList.add('d-none');
          SWITCH_CAM_BUTTON.classList.remove('d-none');
          STATUS.innerText = 'Camera enabled - ready to gather data';
        });

      } catch (error) {
        console.error('Error accessing camera:', error);
        STATUS.innerText = 'Camera access denied. Please check your browser settings.';
        ENABLE_CAM_BUTTON.disabled = false;
        ENABLE_CAM_BUTTON.innerText = 'Retry Camera Access';
      }
    }

    async function switchCamera() {
      if (!videoPlaying) return;
      
      // Stop all tracks from the current stream
      if (stream) {
        stream.getTracks().forEach(track => track.stop());
      }
      
      // Toggle facing mode
      currentFacingMode = currentFacingMode === 'user' ? 'environment' : 'user';
      
      try {
        STATUS.innerText = 'Switching camera...';
        
        // Request the new camera stream
        const constraints = {
          video: {
            facingMode: currentFacingMode,
            width: { ideal: 640 },
            height: { ideal: 480 }
          }
        };
        
        stream = await navigator.mediaDevices.getUserMedia(constraints);
        VIDEO.srcObject = stream;
        
        STATUS.innerText = `Camera switched to ${currentFacingMode === 'user' ? 'front' : 'back'} camera`;
      } catch (error) {
        console.error('Error switching camera:', error);
        STATUS.innerText = `Failed to switch camera: ${error.message}`;
      }
    }

    // Add mobile-specific styles
    const mobileStyles = `
      @media (max-width: 768px) {
        #webcam {
          width: 100%;
          max-width: 640px;
          height: auto;
          border-radius: 8px;
          margin-bottom: 20px;
        }

        .btn {
          padding: 15px;
          font-size: 16px;
          margin-bottom: 10px;
          touch-action: manipulation;
        }

        #status {
          font-size: 14px;
          padding: 10px;
          background-color: #f8f9fa;
          border-radius: 5px;
          margin: 10px 0;
        }

        .container {
          padding: 10px;
        }
      }
    `;

    const styleSheet = document.createElement("style");
    styleSheet.textContent = mobileStyles;
    document.head.appendChild(styleSheet);

    // Function to gather data for the different classes
    function gatherDataForClass() {
      let classId = parseInt(this.getAttribute('data-1hot'));
      let className = this.getAttribute('data-name');
      
      if (videoPlaying) {
        if (gatherDataState === STOP_DATA_GATHER) {
          gatherDataState = classId;
          this.innerText = `Gathering for ${className}`;
          this.classList.remove('btn-primary');
          this.classList.add('btn-danger');
          
          // Initialize counts if needed
          if (!examplesCount[classId]) {
            examplesCount[classId] = 0;
          }
          
          // Start the image capture process
          setTimeout(function() {
            captureFrame();
          }, 100);
          
        } else {
          gatherDataState = STOP_DATA_GATHER;
          this.innerText = `Gather ${className} Data`;
          this.classList.remove('btn-danger');
          this.classList.add('btn-primary');
        }
      } else {
        STATUS.innerText = 'Please enable the webcam first';
      }
    }

    // Capture image data from the webcam
    function captureFrame() {
      if (gatherDataState !== STOP_DATA_GATHER && videoPlaying) {
        // Get the tensor representation of the webcam image
        let imageFeatures = tf.tidy(function() {
          let videoFrameAsTensor = tf.browser.fromPixels(VIDEO);
          let resizedTensorFrame = tf.image.resizeBilinear(
            videoFrameAsTensor, 
            [MOBILE_NET_INPUT_HEIGHT, MOBILE_NET_INPUT_WIDTH]
          );
          let normalizedTensorFrame = resizedTensorFrame.div(255);
          
          // Cache the flattened shape to ensure consistency
          window.INPUT_TENSOR_SIZE = MOBILE_NET_INPUT_HEIGHT * MOBILE_NET_INPUT_WIDTH * 3;
          
          return normalizedTensorFrame;
        });
        
        // Store data
        trainingDataInputs.push(imageFeatures);
        
        // Create one-hot encoding for the class
        let classId = gatherDataState;
        let outputTensor = tf.tidy(function() {
          let oneHot = tf.oneHot(classId, CLASS_NAMES.length);
          return oneHot;
        });
        
        trainingDataOutputs.push(outputTensor);
        
        // Update counts and UI
        if (!examplesCount[classId]) {
          examplesCount[classId] = 0;
        }
        examplesCount[classId]++;
        
        STATUS.innerText = `Class ${CLASS_NAMES[classId]} data count: ${examplesCount[classId]}`;
        
        // Collect more data after a short delay
        setTimeout(function() {
          captureFrame();
        }, 100);
      }
    }

    // Train the model and then start predicting
    async function trainAndPredict() {
      if (trainingDataInputs.length === 0) {
        STATUS.innerText = 'Please collect data for at least two classes first';
        return;
      }
      
      // Check if we have data for all classes
      let classDataExists = CLASS_NAMES.map((_, i) => examplesCount[i] && examplesCount[i] > 0);
      if (classDataExists.includes(false)) {
        STATUS.innerText = 'Please collect data for all classes';
        return;
      }
      
      STATUS.innerText = 'Training model...';
      TRAIN_BUTTON.disabled = true;
      
      // Set a smaller batch size and fewer epochs for mobile devices
      const isMobile = /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);
      const batchSize = isMobile ? 16 : 32;
      const epochs = isMobile ? 8 : 10;
      
      try {
        // Determine the exact input shape from the first training example
        let sampleTensor = trainingDataInputs[0];
        let inputShape = sampleTensor.flatten().shape[0];
        
        STATUS.innerText = `Preparing model for input shape: ${inputShape}`;
        
        // Create and train the model
        let model = tf.sequential();
        
        // Use a more mobile-friendly architecture
        model.add(tf.layers.dense({
          inputShape: [inputShape], // Dynamic shape from actual data
          units: isMobile ? 64 : 100, // Smaller network for mobile
          activation: 'relu'
        }));
        
        model.add(tf.layers.dense({
          units: CLASS_NAMES.length,
          activation: 'softmax'
        }));
        
        // Use a lower learning rate on mobile for stability
        model.compile({
          optimizer: tf.train.adam(isMobile ? 0.00005 : 0.0001),
          loss: 'categoricalCrossentropy',
          metrics: ['accuracy']
        });
        
        // Check for memory warning
        if (trainingDataInputs.length > 100 && isMobile) {
          STATUS.innerText = 'Warning: Large dataset may be slow on mobile. Training...';
        }
        
        // Convert data tensors to a single tensor - with memory cleanup
        let xs, ys;
        
        try {
          // Process each tensor one by one to ensure consistent shape
          let processedTensors = [];
          for (let i = 0; i < trainingDataInputs.length; i++) {
            const tensor = trainingDataInputs[i];
            const flatTensor = tf.tidy(() => tensor.reshape([1, inputShape]));
            processedTensors.push(flatTensor);
          }
          
          xs = tf.concat(processedTensors, 0); // Concat along the batch dimension
          ys = tf.concat(trainingDataOutputs);
          
          // Clean up processed tensors
          processedTensors.forEach(t => t.dispose());
          
          // Clear individual tensors to free memory
          trainingDataInputs.forEach(tensor => tensor.dispose());
          trainingDataOutputs.forEach(tensor => tensor.dispose());
          
          // No need to reshape as we've already done it
          // xs = xs.reshape([xs.shape[0], -1]);
          
          // Start training with progress updates
          await model.fit(xs, ys, {
            epochs: epochs,
            batchSize: batchSize,
            callbacks: {
              onBatchEnd: (batch, logs) => {
                // Free memory
                tf.tidy(() => {});
              },
              onEpochEnd: (epoch, logs) => {
                STATUS.innerText = `Training... Epoch ${epoch+1}/${epochs}, Accuracy: ${logs.acc.toFixed(3)}`;
                // Force garbage collection between epochs
                tf.tidy(() => {});
              }
            }
          });
          
          STATUS.innerText = 'Model trained! Predicting...';
          TRAIN_BUTTON.disabled = false;
          
          // Save the input shape for prediction
          window.MODEL_INPUT_SHAPE = inputShape;
          
          // Start predicting
          predict = true;
          predictLoop(model);
          
        } catch (memoryError) {
          console.error('Memory error during training:', memoryError);
          STATUS.innerText = 'Training failed - dataset too large for device memory. Try fewer samples.';
          TRAIN_BUTTON.disabled = false;
          
          // Clean up any tensors
          if (xs) xs.dispose();
          if (ys) ys.dispose();
          return;
        }
      } catch (error) {
        console.error('Error during model training:', error);
        STATUS.innerText = `Training error: ${error.message}. Try again with less data.`;
        TRAIN_BUTTON.disabled = false;
      }
    }

    // Prediction loop with memory management
    function predictLoop(model) {
      if (!predict || !videoPlaying) return;
      
      tf.tidy(function() {
        // Get current frame as a tensor
        let imageFeatures = tf.browser.fromPixels(VIDEO);
        let resizedTensorFrame = tf.image.resizeBilinear(
          imageFeatures, 
          [MOBILE_NET_INPUT_HEIGHT, MOBILE_NET_INPUT_WIDTH]
        );
        let normalizedTensorFrame = resizedTensorFrame.div(255);
        
        // Reshape using the same shape as training
        let inputShape = window.MODEL_INPUT_SHAPE || normalizedTensorFrame.flatten().shape[0];
        let reshapedImage = normalizedTensorFrame.reshape([1, inputShape]);
        
        // Make prediction
        let prediction = model.predict(reshapedImage);
        let classIdx = prediction.argMax(1).dataSync()[0];
        let confidence = prediction.max().dataSync()[0];
        
        STATUS.innerText = `Prediction: ${CLASS_NAMES[classIdx]} (${(confidence * 100).toFixed(2)}%)`;
      });
      
      // Schedule next prediction - slower on mobile to reduce battery/heat
      const isMobile = /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);
      setTimeout(function() {
        predictLoop(model);
      }, isMobile ? 500 : 200);
    }

    // Reset the model and data
    function reset() {
      trainingDataInputs = [];
      trainingDataOutputs = [];
      examplesCount = [];
      predict = false;
      
      STATUS.innerText = 'Model and data reset. Ready to collect new samples.';
      
      // Reset button states
      TRAIN_BUTTON.disabled = false;
      dataCollectorButtons.forEach(btn => {
        btn.innerText = `Gather ${btn.getAttribute('data-name')} Data`;
        btn.classList.remove('btn-danger');
        btn.classList.add('btn-primary');
      });
    }

    // Check if TensorFlow.js is loaded
    document.addEventListener('DOMContentLoaded', function() {
      if (tf) {
        document.getElementById('loadingIndicator').style.visibility = 'hidden';
        STATUS.innerText = 'TensorFlow.js loaded successfully. Click "Enable Webcam" to start.';
      }
    });
  </script>
</main>
<script src="/docs/5.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-C6RzsynM9kWDrMNeT87bh95OGNyZPhcTNXj1NW7RuBCsyN/o0jlpcV8Qyq46cDfL" crossorigin="anonymous"></script>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-T3c6CoIi6uLrA9TneNEoa7RxnatzjcDSCmG1MXxSR1GAsXEV/Dwwykc2MPK8M2HN" crossorigin="anonymous">
    </body>
</html>
